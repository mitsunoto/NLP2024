{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек"
      ],
      "metadata": {
        "id": "5cBfJE9btwa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lxml import etree # библиотека для работы с XML-структурами"
      ],
      "metadata": {
        "id": "Lv3sIPybOGLo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Парсинг словаря OpenCorpora"
      ],
      "metadata": {
        "id": "sH-agel1t02s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_opencorpora_dict(file_path):\n",
        "    tree = etree.parse(file_path)\n",
        "    root = tree.getroot() # получаем корневой элемент XML-дерева\n",
        "\n",
        "    lemmata = {} # инициализация словаря для хранения лемм\n",
        "    for lemma in root.findall(\".//lemma\"): # проходим по всем леммам в словаре\n",
        "        lemma_element = lemma.find(\".//l\") # извлекаем следующий элемент леммы\n",
        "\n",
        "        if lemma_element is not None:\n",
        "            lemma_text = lemma_element.get('t') # извлекаем словарную форму слова\n",
        "            pos_elements = lemma.findall(\".//g\") # извлекаем атрибуты, содержащие грамматическую информацию о слове (часть речи и др.)\n",
        "            pos = {g.get('v') for g in pos_elements if g is not None}  # сохраняем часть речи (и другие возможные атрибуты) как множество\n",
        "            forms = [f.get('t') for f in lemma.findall(\".//f\")] # извлекаем все возможные формы слова (например, склонения, спряжения)\n",
        "\n",
        "            # связываем каждую форму слова с леммой и частью речи\n",
        "            for form in forms:\n",
        "                lemmata[form] = (lemma_text, pos)\n",
        "\n",
        "    return lemmata # функция возвращает словарь, где ключ — форма слова, а значение — кортеж с леммой и частью речи"
      ],
      "metadata": {
        "id": "Nys8viMiOIJA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Лемматизация текста"
      ],
      "metadata": {
        "id": "iXihtHItt5LK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для извлечения части речи из атрибутов слова (тегов)."
      ],
      "metadata": {
        "id": "UXGqYlM8t8-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_part_of_speech(tags):\n",
        "    # множество всех возможных тегов частей речи\n",
        "    pos_map = {\n",
        "        'NOUN': 'NOUN',  # Существительное\n",
        "        'ADJF': 'ADJ',   # Прилагательное\n",
        "        'VERB': 'VERB',  # Глагол\n",
        "        'ADV': 'ADV',    # Наречие\n",
        "        'PRCL': 'PRCL',  # Частица\n",
        "        'PR': 'PR',      # Предлог\n",
        "        'NUMR': 'NUM',   # Числительное\n",
        "        'NPRO': 'NPRO',  # Местоимение\n",
        "        'ADVB': 'ADVB',  # Наречие\n",
        "        'PREP': 'PREP'   # Предлог\n",
        "    }\n",
        "\n",
        "    # проходим по тегам и ищем совпадение среди тегов из множества выше\n",
        "    for tag in tags:\n",
        "        if tag in pos_map:\n",
        "            return pos_map[tag] # функция возвращает часть речи в случае, если тег нашел совпадение в словаре тегов частей речи\n",
        "\n",
        "    return 'UNKNOWN' # функция возвращает строку 'неизвестно', если части речи не была обнаружена среди тегов"
      ],
      "metadata": {
        "id": "cuMbCyaoTmAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_part_of_speech(tags):\n",
        "    # множество всех возможных тегов частей речи\n",
        "    pos_tags = {\n",
        "        'NOUN',  # Существительное\n",
        "        'ADJF',  # Прилагательное\n",
        "        'VERB',  # Глагол\n",
        "        'ADV',   # Наречие\n",
        "        'PRCL',  # Частица\n",
        "        'PR',    # Предлог\n",
        "        'NUMR',  # Числительное\n",
        "        'NPRO',  # Местоимение\n",
        "        'ADVB',  # Наречие\n",
        "        'PREP'   # Предлог\n",
        "    }\n",
        "\n",
        "    # Проходим по тегам и ищем совпадение среди тегов из множества\n",
        "    for tag in tags:\n",
        "        if tag in pos_tags:\n",
        "            return tag  # Возвращаем тег, если нашли совпадение\n",
        "\n",
        "    return 'UNKNOWN'  # Возвращаем 'UNKNOWN', если часть речи не была обнаружена среди тегов"
      ],
      "metadata": {
        "id": "eTLfi_xR1bLU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_text(text, lemmata):\n",
        "    tokens = text.split() # токенизация текста (разбивка на отдельные слова)\n",
        "    lemmatized_words = [] # инициализация множества для хранения лемматизированных слов\n",
        "\n",
        "    for token in tokens: # проходим по каждому токену\n",
        "        token = token.lower().replace('ё', 'е').strip('.,!?')  # нормализация\n",
        "        if token in lemmata: # проверяем, есть ли слово в словаре лемм\n",
        "            lemma, pos = lemmata[token] # получаем лемму и множество тегов\n",
        "            part_of_speech = extract_part_of_speech(pos) # извлекаем часть речи из тегов\n",
        "            lemmatized_words.append(f\"{token}{{{lemma}={part_of_speech}}}\") # формируем результат для каждого токена\n",
        "        else:\n",
        "            lemmatized_words.append(f\"{token}{{UNKNOWN=UNKNOWN}}\")\n",
        "\n",
        "    return ' '.join(lemmatized_words) # функция возвращает текст с лемматизированными словами"
      ],
      "metadata": {
        "id": "oOPGMfjqOOso"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main"
      ],
      "metadata": {
        "id": "br2FkUEa0pne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmata_dict = parse_opencorpora_dict('dict.opcorpora.xml')"
      ],
      "metadata": {
        "id": "GKUcxFJEOQRQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Стала стабильнее экономическая и политическая обстановка, предприятия вывели из тени зарплаты сотрудников.\"\n",
        "print(lemmatize_text(text, lemmata_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2dA1FjuOTpJ",
        "outputId": "c9ba1233-2417-4547-9d2b-cea9636ac8e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "стала{стал=VERB} стабильнее{стабильнее=UNKNOWN} экономическая{экономический=ADJF} и{и=NOUN} политическая{политический=ADJF} обстановка{обстановка=NOUN} предприятия{предприятие=NOUN} вывели{вывел=VERB} из{иза=NOUN} тени{тень=NOUN} зарплаты{зарплата=NOUN} сотрудников{сотрудник=NOUN}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Все Гришины одноклассники уже побывали за границей, он был чуть ли не единственным, кого не вывозили никуда дальше Красной Пахры.\"\n",
        "print(lemmatize_text(text, lemmata_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xwGYdWfOVnZ",
        "outputId": "cb455c3c-5737-4682-d8ba-5e7d42ef8777"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "все{весь=ADJF} гришины{гришин=ADJF} одноклассники{одноклассник=NOUN} уже{уже=PRCL} побывали{побывал=VERB} за{за=PREP} границей{граница=NOUN} он{он=NPRO} был{есть=VERB} чуть{чуть=UNKNOWN} ли{ли=NOUN} не{не=PRCL} единственным{единственный=ADJF} кого{кто=NPRO} не{не=PRCL} вывозили{вывозил=VERB} никуда{никуда=ADVB} дальше{дальше=UNKNOWN} красной{красный=ADJF} пахры{пахра=NOUN}\n"
          ]
        }
      ]
    }
  ]
}
